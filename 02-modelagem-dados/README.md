# üóÑÔ∏è M√≥dulo 2: Modelagem e Armazenamento de Dados

**Dura√ß√£o:** 4-5 semanas | **N√≠vel:** Intermedi√°rio

## üìã Vis√£o Geral

Aprenda a modelar, armazenar e organizar dados para an√°lises eficientes em grande escala.

## üéØ Objetivos

- ‚úÖ Modelagem dimensional (Star, Snowflake)
- ‚úÖ Data Vault 2.0
- ‚úÖ Data Warehouses modernos
- ‚úÖ Data Lakes e Lakehouses
- ‚úÖ Formatos de arquivo otimizados
- ‚úÖ Particionamento e indexa√ß√£o

## üìö Conte√∫do

### 1. Modelagem Dimensional

**Star Schema:**
```
      DIM_PRODUTO
           |
DIM_DATA - FACT_VENDAS - DIM_CLIENTE
           |
      DIM_LOJA
```

- Fact Tables (m√©tricas, FK's)
- Dimension Tables (contexto, SK's)
- Slowly Changing Dimensions (SCD Type 1, 2, 3)
- Surrogate Keys vs Natural Keys

**Snowflake Schema:**
- Dimens√µes normalizadas
- Menos redund√¢ncia
- Mais joins necess√°rios

### 2. Data Vault 2.0

**Componentes:**
- **Hubs**: Entidades de neg√≥cio (Cliente, Produto)
- **Links**: Relacionamentos (Pedido)
- **Satellites**: Atributos descritivos

**Vantagens:**
- Audit√°vel (hist√≥rico completo)
- Escal√°vel (paraleliza√ß√£o)
- Flex√≠vel (adicionar fontes)

### 3. Data Warehouses

**Snowflake:**
- Separa√ß√£o compute/storage
- Auto-scaling
- Zero-copy cloning
- Time Travel

**AWS Redshift:**
- Columnar storage
- MPP architecture
- Distribution styles (KEY, ALL, EVEN)
- Sort keys

**Google BigQuery:**
- Serverless
- SQL ANSI
- Streaming ingestion
- Partitioning/Clustering

### 4. Data Lakes

**Arquitetura:**
```
Bronze (Raw) ‚Üí Silver (Cleaned) ‚Üí Gold (Curated)
```

**Governan√ßa:**
- Data Catalog (Glue, Purview)
- Data Lineage
- Access control (IAM, RBAC)
- Data Quality

### 5. Formatos de Arquivo

| Formato | Tipo | Compress√£o | Uso |
|---------|------|------------|-----|
| **Parquet** | Columnar | Snappy | Analytics, Spark |
| **ORC** | Columnar | Zlib | Hive, Presto |
| **Avro** | Row | Deflate | Streaming, Kafka |
| **Delta Lake** | Lakehouse | Snappy | ACID, Time Travel |
| **Iceberg** | Lakehouse | Various | Schema evolution |

### 6. Otimiza√ß√µes

**Particionamento:**
```python
# By date
/data/year=2024/month=01/day=15/data.parquet

# By category
/data/category=electronics/data.parquet

# Multi-level
/data/year=2024/month=01/category=books/data.parquet
```

**Bucketing:**
```sql
CREATE TABLE sales
USING parquet
PARTITIONED BY (year, month)
CLUSTERED BY (customer_id) INTO 100 BUCKETS;
```

## üéØ Exerc√≠cios

### Exerc√≠cio 1: Star Schema
Modelar DW para e-commerce:
- Fatos: Vendas, Devolu√ß√µes
- Dimens√µes: Cliente, Produto, Tempo, Loja

### Exerc√≠cio 2: SCD Type 2
Implementar hist√≥rico de mudan√ßas em dimens√µes

### Exerc√≠cio 3: Data Lake
Criar pipeline Bronze‚ÜíSilver‚ÜíGold com valida√ß√µes

## üìñ Recursos

- **Livro**: "The Data Warehouse Toolkit" (Kimball)
- **Curso**: Snowflake Hands-on Essentials
- **Docs**: Delta Lake Documentation

## ‚úÖ Checklist

- [ ] Criei Star Schema completo
- [ ] Implementei Data Vault
- [ ] Usei Snowflake/Redshift/BigQuery
- [ ] Organizei Data Lake em camadas
- [ ] Otimizei com particionamento
- [ ] Escolho formato certo para cada caso

## üöÄ Pr√≥ximos Passos

‚û°Ô∏è **[M√≥dulo 3: Processamento em Larga Escala](../03-processamento-larga-escala/)**
