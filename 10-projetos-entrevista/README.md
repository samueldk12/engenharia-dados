# Projetos de Entrevista - Data Engineering

ColeÃ§Ã£o completa de projetos que caem em entrevistas de emprego para **Senior Data Engineer**, organizados por nÃ­vel de arquitetura.

## ğŸ“‹ Ãndice

### ğŸ”§ Low Level Architecture (ImplementaÃ§Ã£o & Algoritmos)
1. [**Log Processing System**](#1-log-processing-system) - Parse e anÃ¡lise de logs em tempo real
2. [**URL Shortener**](#2-url-shortener) - Sistema de encurtamento de URLs com analytics
3. [**Rate Limiter**](#3-rate-limiter) - ImplementaÃ§Ã£o de estratÃ©gias de rate limiting
4. [**Cache System**](#4-cache-system) - Sistema de cache distribuÃ­do (LRU/LFU)

### ğŸ—ï¸ High Level Architecture (Design de Sistemas)
5. [**Ride-Sharing System**](#5-ride-sharing-system) - Sistema como Uber (matching em tempo real)
6. [**E-commerce Analytics Pipeline**](#6-e-commerce-analytics-pipeline) - Pipeline completo de analytics
7. [**Distributed Job Scheduler**](#7-distributed-job-scheduler) - Scheduler distribuÃ­do escalÃ¡vel
8. [**Real-time Fraud Detection**](#8-real-time-fraud-detection) - DetecÃ§Ã£o de fraude em tempo real

---

## ğŸ”§ LOW LEVEL ARCHITECTURE

Projetos focados em **implementaÃ§Ã£o**, **algoritmos**, **estruturas de dados** e **otimizaÃ§Ã£o de cÃ³digo**.

### 1. Log Processing System

**Pergunta comum:** "Como vocÃª processaria 10GB de logs por segundo?"

**Desafios:**
- Parse eficiente de logs (mÃºltiplos formatos)
- AgregaÃ§Ã£o em tempo real
- DetecÃ§Ã£o de anomalias
- Escrita eficiente para storage

**Estrutura:**
```
01-log-processing-system/
â”œâ”€â”€ README.md                  # Requisitos e decisÃµes de design
â”œâ”€â”€ log_parser.py             # Parser otimizado (regex vs split)
â”œâ”€â”€ aggregator.py             # AgregaÃ§Ã£o em janelas de tempo
â”œâ”€â”€ anomaly_detector.py       # DetecÃ§Ã£o de anomalias
â”œâ”€â”€ writer.py                 # Batch writing otimizado
â”œâ”€â”€ benchmarks/               # Benchmarks de performance
â””â”€â”€ tests/                    # Testes unitÃ¡rios
```

**Conceitos Cobertos:**
- String parsing eficiente
- Sliding window aggregation
- Memory-efficient processing
- Batch vs streaming trade-offs
- Time complexity analysis (O(n) vs O(nÂ²))

**Perguntas de Follow-up:**
- Como vocÃª otimizaria para 100GB/s?
- Como lidaria com logs out-of-order?
- Como garantiria exactly-once processing?

---

### 2. URL Shortener

**Pergunta comum:** "Design um sistema de encurtamento de URLs como bit.ly"

**Desafios:**
- GeraÃ§Ã£o de IDs Ãºnicos e curtos
- ConversÃ£o Base62
- Collision handling
- EstatÃ­sticas de acesso
- ExpiraÃ§Ã£o de URLs

**Estrutura:**
```
02-url-shortener/
â”œâ”€â”€ README.md
â”œâ”€â”€ id_generator.py           # Snowflake ID / Base62 encoding
â”œâ”€â”€ url_shortener.py          # Core logic
â”œâ”€â”€ storage.py                # Storage abstraction (Redis/PostgreSQL)
â”œâ”€â”€ analytics.py              # Click analytics
â”œâ”€â”€ api.py                    # FastAPI endpoints
â””â”€â”€ tests/
```

**Conceitos Cobertos:**
- ID generation strategies (UUID vs Snowflake vs Counter)
- Base conversion (Base10 â†’ Base62)
- Hash collision resolution
- Database indexing
- Caching strategies

**Perguntas de Follow-up:**
- Como garantir IDs Ãºnicos em sistema distribuÃ­do?
- Como escalar para 1 bilhÃ£o de URLs?
- Como evitar ataques de brute-force?

---

### 3. Rate Limiter

**Pergunta comum:** "Implemente um rate limiter que suporte 1000 req/min por usuÃ¡rio"

**Desafios:**
- MÃºltiplas estratÃ©gias (Token Bucket, Sliding Window, Fixed Window)
- ImplementaÃ§Ã£o distribuÃ­da
- Performance (<1ms overhead)
- PrecisÃ£o vs throughput trade-off

**Estrutura:**
```
03-rate-limiter/
â”œâ”€â”€ README.md
â”œâ”€â”€ strategies/
â”‚   â”œâ”€â”€ token_bucket.py       # Token bucket algorithm
â”‚   â”œâ”€â”€ sliding_window.py     # Sliding window log
â”‚   â”œâ”€â”€ fixed_window.py       # Fixed window counter
â”‚   â””â”€â”€ leaky_bucket.py       # Leaky bucket
â”œâ”€â”€ distributed_limiter.py    # Redis-based distribuÃ­do
â”œâ”€â”€ decorator.py              # Python decorator para APIs
â”œâ”€â”€ benchmarks/               # ComparaÃ§Ã£o de performance
â””â”€â”€ tests/
```

**Conceitos Cobertos:**
- Rate limiting algorithms
- Atomic operations (Redis INCR)
- Distributed coordination
- Time window handling
- Memory efficiency

**Perguntas de Follow-up:**
- Qual estratÃ©gia Ã© melhor para bursts?
- Como sincronizar entre mÃºltiplos servidores?
- Como lidar com clock skew?

---

### 4. Cache System

**Pergunta comum:** "Implemente um cache LRU thread-safe com TTL"

**Desafios:**
- Eviction policies (LRU, LFU, FIFO)
- Thread safety
- TTL management
- Memory limits
- SerializaÃ§Ã£o eficiente

**Estrutura:**
```
04-cache-system/
â”œâ”€â”€ README.md
â”œâ”€â”€ policies/
â”‚   â”œâ”€â”€ lru_cache.py          # LRU com OrderedDict
â”‚   â”œâ”€â”€ lfu_cache.py          # LFU com heap
â”‚   â””â”€â”€ arc_cache.py          # Adaptive Replacement Cache
â”œâ”€â”€ distributed_cache.py      # Redis-based
â”œâ”€â”€ ttl_manager.py            # TTL com lazy deletion
â”œâ”€â”€ serialization.py          # Pickle vs msgpack vs JSON
â”œâ”€â”€ benchmarks/
â””â”€â”€ tests/
```

**Conceitos Cobertos:**
- Cache eviction algorithms
- Data structures (OrderedDict, heap, doubly-linked list)
- Thread synchronization (locks, RLock)
- Memory management
- Serialization trade-offs

**Perguntas de Follow-up:**
- LRU vs LFU: quando usar cada um?
- Como implementar write-through vs write-back?
- Como escalar cache entre mÃºltiplas mÃ¡quinas?

---

## ğŸ—ï¸ HIGH LEVEL ARCHITECTURE

Projetos focados em **design de sistemas**, **escalabilidade**, **distribuiÃ§Ã£o** e **trade-offs**.

### 5. Ride-Sharing System (Uber-like)

**Pergunta comum:** "Design um sistema de ride-sharing como Uber"

**Desafios:**
- Geolocation matching em tempo real
- Routing otimizado
- Surge pricing
- Disponibilidade de motoristas
- Escalabilidade global

**Estrutura:**
```
05-ride-sharing-system/
â”œâ”€â”€ README.md                 # Arquitetura completa
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ system_design.md      # Diagrama de componentes
â”‚   â”œâ”€â”€ data_models.md        # Schema de dados
â”‚   â””â”€â”€ scaling.md            # EstratÃ©gia de escala
â”œâ”€â”€ location_service/
â”‚   â”œâ”€â”€ geohash.py            # Geohashing para proximidade
â”‚   â”œâ”€â”€ quadtree.py           # QuadTree para busca espacial
â”‚   â””â”€â”€ matching_engine.py    # Algoritmo de matching
â”œâ”€â”€ pricing_service/
â”‚   â”œâ”€â”€ surge_calculator.py   # CÃ¡lculo de surge pricing
â”‚   â””â”€â”€ eta_estimator.py      # Estimativa de ETA
â”œâ”€â”€ trip_service/
â”‚   â””â”€â”€ state_machine.py      # State machine de trip
â””â”€â”€ infrastructure/
    â”œâ”€â”€ kafka_topics.md       # Event streaming
    â”œâ”€â”€ redis_schema.md       # Real-time data
    â””â”€â”€ cassandra_schema.md   # Trip history
```

**Conceitos Cobertos:**
- Geospatial indexing (Geohash, S2, QuadTree)
- Real-time matching algorithms
- Event-driven architecture
- CAP theorem trade-offs
- Database sharding por regiÃ£o

**Capacidade:**
- 1M motoristas online
- 10M passageiros ativos
- 100K trips/min
- <1 segundo para matching

**Perguntas de Follow-up:**
- Como garantir consistency em matching?
- Como lidar com network partitions?
- Como calcular surge pricing em tempo real?

---

### 6. E-commerce Analytics Pipeline

**Pergunta comum:** "Design um pipeline de analytics para e-commerce (Amazon-scale)"

**Desafios:**
- IngestÃ£o de mÃºltiplas fontes (clickstream, transaÃ§Ãµes, inventory)
- ETL de 10TB+ por dia
- Real-time + batch analytics
- Data quality e deduplicaÃ§Ã£o
- GDPR compliance

**Estrutura:**
```
06-ecommerce-analytics-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ data_flow.md          # Diagrama de fluxo de dados
â”‚   â”œâ”€â”€ lambda_architecture.md # Lambda vs Kappa
â”‚   â””â”€â”€ data_warehouse.md     # Star schema design
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ kafka_producers/      # Event producers
â”‚   â”œâ”€â”€ change_data_capture/  # CDC para databases
â”‚   â””â”€â”€ api_collectors/       # Coleta de APIs externas
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ spark_jobs/           # Batch ETL (PySpark)
â”‚   â”œâ”€â”€ flink_jobs/           # Stream processing
â”‚   â””â”€â”€ dbt_models/           # Data transformation (dbt)
â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ olap_cubes/           # OLAP cubes (Druid/Clickhouse)
â”‚   â”œâ”€â”€ ml_features/          # Feature store
â”‚   â””â”€â”€ dashboards/           # Superset/Tableau
â””â”€â”€ orchestration/
    â””â”€â”€ airflow_dags/         # DAGs de orquestraÃ§Ã£o
```

**Conceitos Cobertos:**
- Lambda vs Kappa architecture
- Data lake vs data warehouse
- Star schema vs snowflake schema
- Slowly changing dimensions (SCD Type 2)
- Data partitioning strategies

**MÃ©tricas:**
- 10TB data/day
- 100K events/sec (real-time)
- <5 min latency (streaming)
- <2 hours latency (batch)

**Perguntas de Follow-up:**
- Como garantir data quality?
- Como lidar com late-arriving data?
- Como implementar GDPR (right to be forgotten)?

---

### 7. Distributed Job Scheduler

**Pergunta comum:** "Design um sistema de job scheduling distribuÃ­do (Airflow-like)"

**Desafios:**
- DAG execution
- Distributed coordination
- Failure recovery
- Resource management
- Priority scheduling

**Estrutura:**
```
07-distributed-job-scheduler/
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ system_design.md
â”‚   â”œâ”€â”€ consensus.md          # Raft/Paxos para leader election
â”‚   â””â”€â”€ fault_tolerance.md
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ dag_parser.py         # Parse de DAGs
â”‚   â”œâ”€â”€ topological_sort.py   # OrdenaÃ§Ã£o topolÃ³gica
â”‚   â”œâ”€â”€ executor.py           # Task execution
â”‚   â””â”€â”€ retry_policy.py       # Exponential backoff
â”œâ”€â”€ coordination/
â”‚   â”œâ”€â”€ leader_election.py    # Leader election (ZooKeeper/etcd)
â”‚   â”œâ”€â”€ distributed_lock.py   # Distributed locking
â”‚   â””â”€â”€ health_check.py       # Health monitoring
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ metadata_store.py     # PostgreSQL para metadata
â”‚   â””â”€â”€ state_machine.py      # State machine de tasks
â””â”€â”€ workers/
    â”œâ”€â”€ worker_pool.py        # Pool de workers
    â””â”€â”€ resource_manager.py   # CPU/memory management
```

**Conceitos Cobertos:**
- Directed Acyclic Graphs (DAG)
- Distributed consensus (Raft/Paxos)
- Leader election
- At-least-once vs exactly-once execution
- Graceful degradation

**Capacidade:**
- 10K DAGs
- 1M tasks/day
- 1K concurrent workers
- <10 sec scheduling latency

**Perguntas de Follow-up:**
- Como garantir exactly-once execution?
- Como priorizar jobs crÃ­ticos?
- Como escalar horizontalmente?

---

### 8. Real-time Fraud Detection

**Pergunta comum:** "Design um sistema de detecÃ§Ã£o de fraude em tempo real"

**Desafios:**
- LatÃªncia ultra-baixa (<100ms)
- Feature engineering em tempo real
- ML model serving
- False positive vs false negative trade-off
- Concept drift handling

**Estrutura:**
```
08-realtime-fraud-detection/
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ system_design.md
â”‚   â”œâ”€â”€ ml_pipeline.md        # Pipeline de ML
â”‚   â””â”€â”€ feature_engineering.md
â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ real_time_features.py # Features de evento atual
â”‚   â”œâ”€â”€ windowed_features.py  # AgregaÃ§Ãµes de janela
â”‚   â”œâ”€â”€ graph_features.py     # Features de grafo (conexÃµes)
â”‚   â””â”€â”€ feature_store.py      # Redis feature store
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rule_engine.py        # Regras hard-coded
â”‚   â”œâ”€â”€ random_forest.py      # Random Forest
â”‚   â”œâ”€â”€ xgboost_model.py      # XGBoost
â”‚   â””â”€â”€ neural_network.py     # Deep learning (PyTorch)
â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ model_server.py       # FastAPI + model serving
â”‚   â”œâ”€â”€ ensemble.py           # Ensemble de modelos
â”‚   â””â”€â”€ explainability.py     # SHAP values
â”œâ”€â”€ feedback_loop/
â”‚   â”œâ”€â”€ label_collection.py   # Coleta de labels
â”‚   â””â”€â”€ model_retraining.py   # Retreino automÃ¡tico
â””â”€â”€ monitoring/
    â”œâ”€â”€ metrics.py            # Precision, recall, F1
    â””â”€â”€ drift_detection.py    # Concept drift detection
```

**Conceitos Cobertos:**
- Feature engineering para ML
- Model serving at scale
- Online learning vs batch learning
- A/B testing de modelos
- Explainable AI (SHAP, LIME)

**Performance:**
- <100ms latency (p99)
- 100K transactions/sec
- 95%+ precision
- 90%+ recall
- <0.1% false positive rate

**Perguntas de Follow-up:**
- Como lidar com imbalanced data?
- Como detectar concept drift?
- Como explicar decisÃµes de fraude para usuÃ¡rios?

---

## ğŸ“Š ComparaÃ§Ã£o de Projetos

| Projeto | Dificuldade | Tempo TÃ­pico | Conceitos-Chave | Empresas que Perguntam |
|---------|-------------|--------------|-----------------|------------------------|
| **Log Processing** | â­â­ | 45 min | String parsing, aggregation | Google, Amazon, Netflix |
| **URL Shortener** | â­â­ | 45 min | ID generation, encoding | Meta, Twitter, LinkedIn |
| **Rate Limiter** | â­â­â­ | 60 min | Algorithms, distributed systems | Stripe, Shopify, Cloudflare |
| **Cache System** | â­â­â­ | 60 min | Data structures, concurrency | Meta, Google, Amazon |
| **Ride-Sharing** | â­â­â­â­ | 90 min | Geospatial, matching, events | Uber, Lyft, DoorDash |
| **E-commerce Analytics** | â­â­â­â­ | 90 min | Data pipeline, ETL, warehousing | Amazon, Walmart, Shopify |
| **Job Scheduler** | â­â­â­â­â­ | 120 min | Distributed systems, consensus | Airbnb, Netflix, Databricks |
| **Fraud Detection** | â­â­â­â­â­ | 120 min | ML, real-time, feature engineering | PayPal, Stripe, Square |

---

## ğŸ¯ Como Usar Este RepositÃ³rio

### Para Candidatos

1. **Iniciantes**: Comece com projetos Low Level (1-4)
2. **IntermediÃ¡rios**: Tente projetos High Level mais simples (5-6)
3. **AvanÃ§ados**: Desafie-se com projetos complexos (7-8)

### EstratÃ©gia de Estudo

**Semana 1-2**: Low Level Architecture
- Dia 1-3: Log Processing System
- Dia 4-6: URL Shortener
- Dia 7-9: Rate Limiter
- Dia 10-14: Cache System

**Semana 3-4**: High Level Architecture
- Dia 15-19: Ride-Sharing System
- Dia 20-24: E-commerce Analytics
- Dia 25-28: Distributed Job Scheduler

**Semana 5**: Projetos AvanÃ§ados
- Dia 29-35: Real-time Fraud Detection

### Para Entrevistadores

Cada projeto inclui:
- âœ… Requisitos claros
- âœ… Rubricas de avaliaÃ§Ã£o
- âœ… Perguntas de follow-up
- âœ… Red flags comuns
- âœ… SoluÃ§Ãµes de referÃªncia

---

## ğŸ› ï¸ Setup

### Requisitos

```bash
# Python
Python 3.10+

# DependÃªncias principais
pip install redis kafka-python fastapi sqlalchemy pyspark

# Para projetos especÃ­ficos
# Ver requirements.txt em cada pasta
```

### Executar Projeto

```bash
# Exemplo: Log Processing System
cd 01-log-processing-system
pip install -r requirements.txt
python log_parser.py --input logs/sample.log --output results/
```

### Executar Testes

```bash
cd 01-log-processing-system
pytest tests/ -v
```

---

## ğŸ“š Recursos Adicionais

### Livros Recomendados
- **Designing Data-Intensive Applications** - Martin Kleppmann
- **System Design Interview Vol 1 & 2** - Alex Xu
- **Database Internals** - Alex Petrov

### Cursos
- **Grokking the System Design Interview** (educative.io)
- **System Design Primer** (GitHub)
- **Data Engineering Zoomcamp** (DataTalks.Club)

### Sites para Praticar
- [LeetCode System Design](https://leetcode.com/discuss/interview-question/system-design)
- [Pramp](https://www.pramp.com/)
- [interviewing.io](https://interviewing.io/)

---

## ğŸ“ Conceitos por Projeto

### Estruturas de Dados
- **OrderedDict**: Cache LRU
- **Heap**: Cache LFU, Priority Queue
- **Trie**: Autocomplete, IP routing
- **QuadTree**: Geospatial indexing
- **Graph**: Fraud detection, social networks

### Algoritmos
- **Sliding Window**: Rate limiter, metrics
- **Topological Sort**: DAG scheduler
- **Dijkstra**: Routing, shortest path
- **Consistent Hashing**: Distributed cache
- **Bloom Filter**: Deduplication

### Design Patterns
- **Circuit Breaker**: Fault tolerance
- **Bulkhead**: Resource isolation
- **Saga**: Distributed transactions
- **CQRS**: Command-Query separation
- **Event Sourcing**: Audit log

### Sistemas DistribuÃ­dos
- **CAP Theorem**: Consistency vs Availability
- **Consensus**: Raft, Paxos
- **Replication**: Leader-follower, multi-master
- **Sharding**: Horizontal partitioning
- **Load Balancing**: Round-robin, least-connections

---

## ğŸ† NÃ­veis de Senioridade

### Junior (0-2 anos)
Foco: Projetos 1-2
- ImplementaÃ§Ã£o bÃ¡sica
- Testes unitÃ¡rios
- DocumentaÃ§Ã£o

### Mid-Level (2-4 anos)
Foco: Projetos 1-4
- OtimizaÃ§Ã£o de performance
- Trade-offs de design
- Testes de integraÃ§Ã£o

### Senior (4-7 anos)
Foco: Projetos 1-6
- Arquitetura escalÃ¡vel
- Sistemas distribuÃ­dos
- Monitoramento e observabilidade

### Staff/Principal (7+ anos)
Foco: Projetos 1-8
- Design de sistemas complexos
- Cross-functional trade-offs
- Organizational impact

---

## ğŸ“ Template de ResoluÃ§Ã£o

Para cada projeto, use este template:

### 1. Requirements Clarification (5 min)
- Functional requirements
- Non-functional requirements
- Constraints e assumptions

### 2. Back-of-the-Envelope Estimation (5 min)
- QPS (Queries per Second)
- Storage requirements
- Bandwidth

### 3. System Interface Definition (5 min)
- APIs
- Data models

### 4. High-Level Design (10-15 min)
- Componentes principais
- Fluxo de dados
- Diagrama

### 5. Detailed Design (20-30 min)
- Componentes especÃ­ficos
- Algoritmos
- Data structures

### 6. Identifying Bottlenecks (10 min)
- Single points of failure
- Performance bottlenecks
- Scaling strategies

### 7. Trade-offs Discussion (5-10 min)
- Consistency vs Availability
- Latency vs Throughput
- Cost vs Performance

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para adicionar novos projetos:

1. Fork o repositÃ³rio
2. Crie uma branch: `git checkout -b projeto-novo`
3. Siga a estrutura de pastas existente
4. Inclua README, cÃ³digo e testes
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

MIT License - Sinta-se livre para usar em estudos e entrevistas.

---

## â­ Agradecimentos

Projetos inspirados em entrevistas reais de:
- Google, Amazon, Meta, Netflix
- Uber, Lyft, DoorDash
- Stripe, PayPal, Square
- Airbnb, Booking.com
- Databricks, Snowflake

**Boa sorte nas suas entrevistas! ğŸš€**
